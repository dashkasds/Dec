# -*- coding: utf-8 -*-
"""GitHub Smart-seq2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IVe0ryO3F2j0RJmMi83un3se1q1rxQKG
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

"""# Подготовка таблицы соответствия ген - длина транскрипта

Преобразуем таблицу с соответствием генов и их длин.

Файл скачали из ensembl biomart - Homo sapiens, в атрибутах помимо различных обозначений гена и транскрипта выбрали длину транскрипта. Скачали и руками подгрузили.

Переименуем столбец с длиной транскрипта для нашего удобства.
"""

genes_and_length = pd.read_csv('/content/genes_and_TRlength.txt', sep = '\t')

genes_and_length.head()

genes_and_length.rename(columns = {'Transcript length (including UTRs and CDS)' : 'Transcript length'}, inplace = True)

"""Для некоторых генов существует несколько изоформ транскриптов. В таких случаях возьмем самую длинную изоформу из представленных, так как зачастую самый длинная изоформа считается канонической. Укороченные изоформы часто не являются наиболее экспрессированными (скорее редкими), поэтому взятие средней длины для всех изоформ в таком случае скорее повредит анализу. В связи с этим за неимением информации о распределении изоформ в образцах (то есть мы не можем посчитать взвешанное среднее) - возьмем просто самый длинный транскрипт."""

genes_and_length = genes_and_length.loc[genes_and_length.groupby(['Gene stable ID', 'Gene stable ID version', 'Gene name'])['Transcript length'].idxmax()] #группируем gene ID, gene name, для тех у кого одинаковые эти => выбор большей длины транскрипта

"""В нашей таблице с соответствиями гена и длины транскрипта бывают гены, у которых разные id, но одинаковые названия (что конечно немного расстраивает концептуально), например так с геном SZRD1. Добавим индексы:"""

genes_and_length[genes_and_length['Gene name'] == 'SZRD1']

counts = {} # создали пустой словарь
def rename_duplicates(word): # подсчёт появления слова, когда 1 раз - 0, а во второй раз уже +1 и т.д.
    if word in counts:
        counts[word] += 1
        return f"{word}-{counts[word]}" #через - добавляем число к названию
    else:
        counts[word] = 0
        return word

genes_and_length['Gene name'] = genes_and_length['Gene name'].apply(rename_duplicates)

genes_and_length[genes_and_length['Gene name'].str.contains('SZRD1')] # пример

"""# 1) scRNA-seq клеток circulating tumor cell (CTC)

scRNA-seq клетки CTC одного пациента в разное время (7 шт).
Обработка: Trim Galore!, Mapping using STAR (GRCh38), featureCounts.
Samples were retained for further analyses if they had at least 500,000 reads, at least 5,000 genes with non-zero expression and less than 50% of reads mapping to mitochondrial genes.
"""

!wget https://ftp.ncbi.nlm.nih.gov/geo/series/GSE249nnn/GSE249233/suppl/GSE249233%5Fprocessed%5Fcounts%5Fmatrix%2Etxt%2Egz

!gunzip /content/GSE249233_processed_counts_matrix.txt.gz

ctc_df = pd.read_csv('/content/GSE249233_processed_counts_matrix.txt', sep = '\t')

ctc_df.head()

"""В данном эксперименте даны Gene_id.
Поэтому пока добавим просто столбец с длинами по айди генов.
"""

ctc_df.rename(columns = {'ensembl_gene_id': 'Gene stable ID'}, inplace = True)

CTC_length = pd.merge(ctc_df, genes_and_length[['Gene stable ID', 'Transcript length']], on = 'Gene stable ID', how = 'inner')

CTC_length.head()

"""##Возникает вопрос касательно генов с **нулевым каунтом**.
Каунты равные нулю могут быть получены как в из-за биологических причин, тогда для эксперимента на length bias они нам только мешают, так и по техническим, тогда их нужно оставить. Проверим частоту встречаемости нулевых каунтов в зависимости от длины транскриптов на нескольких клетках:
"""

zero_prop = CTC_length.copy()
bin_edges = [11, 250, 500, 1250, 2000, 3500, 5000, 15000, 30000, 70000, 150000, 347561] #разбили на 10 bin по длине
zero_prop["length_bin"] = pd.cut(zero_prop["Transcript length"], bins = bin_edges)

zero_prop.head() # как это выглядит, какой ген в каком bin

zero_proportion_df = zero_prop.groupby("length_bin")[["BC001_01_01_1", "BC001_01_02_1", "BC001_01_03_1", "BC001_01_06_1", "BC001_01_01_2", "BC001_01_03_2", "BC001_01_06_2"]].apply(lambda x: (x == 0).mean())

zero_prop["length_bin"].value_counts() #сколько генов оказалось в каждой из корзин

zero_proportion_df # содержание в каждой корзине значений равных 0 в зависимости от длины

"""Кажется, будто на транскриптов меньшей длины появление каунтов = нулю более вероятно. Это указывает на то, что каунты равные нулю, скорее всего, имеют не биологическое значение (когда ген просто реально не экспрессируется в клетке), а просто не улавливаются во время обработки данных, что само по себе дополнительно указывает на существование length bias. В таком случае не будем удалять такие гены с нулевыми каунтами.

# Построим графики scatter plot для СТС:
Можно заметить, что высокие каунты (log2 >= 10) достигаются только уже для более длинных транскриптов.
"""

sns.scatterplot(data = CTC_length, x = np.log2(CTC_length["Transcript length"] + 1), y = np.log2(CTC_length["BC001_01_03_2"] +1)) #+1 "обезвреживает" 0
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("BC001_01_03_2")
plt.show()

sns.scatterplot(data = CTC_length, x = np.log2(CTC_length["Transcript length"] + 1), y = np.log2(CTC_length["BC001_01_03_1"] +1))
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("BC001_01_03_1")
plt.show()

"""# Создадим общую таблицу для результатов"""

names_cells = list(CTC_length.columns)[1:-1]
name_experiment = 7 * ['CTC Human']
organism = 7 * ['Homo sapiens']
align_t = 7 * ['STAR']
quant_t = 7 * ['FeatureCounts']

correlation_results = pd.DataFrame({'Experiment' : name_experiment, 'Cell_ID' : names_cells, 'Organism' : organism, 'Alignment' : align_t, 'Quantification' : quant_t})

CTC_length.head()

correlation_results.head()

"""# Посчитаем корреляцию Спирмена

H0: Длина транскрипта и значение каунта не коррелируют
H1: Длина транскрипта и значение каунта коррелируют

Уровень значимости возьмем p-value <= 0.05

**При анализе более 100 клеток в конце(ниже) провели поправку на множественность.**
"""

from scipy.stats import spearmanr

# Считаем корреляцию Спирмена для всех клеток по порядку

coeff_sp = []
p_val = []
for cell in names_cells:
  correlation, p_value = spearmanr(CTC_length[cell], CTC_length["Transcript length"])
  coeff_sp.append(correlation)
  p_val.append(p_value)

correlation_results['Spearman coefficient'] = coeff_sp
correlation_results['Spearman p-value'] = p_val

correlation_results.head()

"""## Shuffle test

Выше замечена между длиной транскрипта и числом прочтений. Проверим, что она обоснована реально именно длинами последовательности, а не чем-нибудь другим. Перемешаем наши данные и снова найдем коэффициенты корреляции Спирмена.
Нулевая гипотеза теста с перемешиванием: наблюдаемая корреляция между длиной транскрипта и каунтами -- из-за случайности, а не из-за систематического length bias.

**Сравнивая реальную корреляцию (где длина и количество отсчетов естественным образом связаны) с перетасованной корреляцией (где соединение случайное), можно определить, является ли наблюдаемая корреляция более сильной, чем можно было бы ожидать при случайном совпадении. Если корреляция в перетасованных данных намного слабее, это дает более веские доказательства того, что связь между длиной гена и его количеством реальна, а не обусловлена смешивающими факторами или случайностью.**
"""

CTC_length_shuffle = CTC_length.copy()

CTC_length_shuffle["Transcript length"] = CTC_length_shuffle["Transcript length"].sample(frac = 1, random_state = 30).reset_index(drop=True)
# 30 - любое число чтобы зафиксировать одинаковый результат нашего рандомного перемешивания

# Считаем корреляцию Спирмена для всех клеток по порядку, но ПОСЛЕ ПЕРЕМЕШИВАНИЯ

coeff_sp_sh = []
p_val_sh = []
for cell in names_cells:
  correlation, p_value = spearmanr(CTC_length_shuffle[cell], CTC_length_shuffle["Transcript length"])
  coeff_sp_sh.append(correlation)
  p_val_sh.append(p_value)

correlation_results['Spearman coeff after SHUFFLE'] = coeff_sp_sh
correlation_results['Spearman p-value after SHUFFLE'] = p_val_sh

correlation_results.head()

"""# Критерий Колмогорова — Смирнова

Сравним распределения каунтов между генами с длинными транскриптами и генами с короткими транскриптами. Если существует length bias, то каунты таких групп должны отличаться распределением друг от друга. В целом такой тест показывает, являются ли различия между двумя группами данных статистически значимыми.

H0: обе группы имеют одинаковое распределение

Сначала поймем, как разбить гены на длинные и короткие. Для этого найдем их квантили.
"""

CTC_length["Transcript length"].quantile([0.25, 0.5, 0.75])

# Квантиль 0.75 возьмем в качестве порога между длинными и короткими транскриптами. Создадим для них две отдельные таблицы

CTC_long = CTC_length[CTC_length["Transcript length"] >= 4365.75]
CTC_short = CTC_length[CTC_length["Transcript length"] < 4365.75]

CTC_long.head()

CTC_short.head()

from scipy import stats

# Посчитаем критерий КС для всех клеток по порядку

coeff_KS = []
p_val_KS = []
for cell in names_cells:
  statistic, p_value = stats.ks_2samp(CTC_short[cell], CTC_long[cell])
  coeff_KS.append(statistic)
  p_val_KS.append(p_value)

correlation_results['KS coeff'] = coeff_KS
correlation_results['KS p-value'] = p_val_KS
correlation_results.head()

"""## Повторим критерий Колмогорова-Смирнова, но после перемешивания

Для этого *сначала* перемешиваем (воспользуемся уже готовым CTC_length_shuffle), а потом уже разделяем на две группы
"""

# Квантиль 0.75 возьмем в качестве порога между длинными и короткими транскриптами. Создадим для них две отдельные таблицы

CTC_long_sh = CTC_length_shuffle[CTC_length_shuffle["Transcript length"] >= 4365.75]
CTC_short_sh = CTC_length_shuffle[CTC_length_shuffle["Transcript length"] < 4365.75]

# Посчитаем критерий КС для всех клеток по порядку, но уже ПОСЛЕ ПЕРЕМЕШИВАНИЯ

coeff_KS_sh = []
p_val_KS_sh = []
for cell in names_cells:
  statistic, p_value = stats.ks_2samp(CTC_short_sh[cell], CTC_long_sh[cell])
  coeff_KS_sh.append(statistic)
  p_val_KS_sh.append(p_value)

correlation_results['KS coeff after SHUFFLE'] = coeff_KS_sh
correlation_results['KS p-value after SHUFFLE'] = p_val_KS_sh
correlation_results.head()

"""Получили, что на исходных данных распределения каунтов для длинных и коротких транскриптов статистически значимо отличаются (а значит и сами эти группы), а при перемешивание такая разница исчезает. Благодаря этому эксперименту можно сделать вывод о влиянии именно длины транскрипта на разницу между двух групп каунтов, что в очереденой раз указывает на существование length bias.

# Нормализация каунтов

Нормализуем каунты по длине и посмотрим, помогает ли это нам с length bias
"""

CTC_length_TPM = CTC_length.copy()

CTC_length_TPM

CTC_length_TPM['length kb'] = CTC_length_TPM['Transcript length'] / 1000

for cell in names_cells:
  CTC_length_TPM[cell] = CTC_length_TPM[cell] / CTC_length_TPM['length kb']
  scaling_factor = CTC_length_TPM[cell].sum() / 1e6
  CTC_length_TPM[cell] = CTC_length_TPM[cell] / scaling_factor

CTC_length_TPM.head()

sns.scatterplot(data = CTC_length, x = np.log2(CTC_length["Transcript length"] + 1), y = np.log2(CTC_length["BC001_01_06_1"] +1))
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("BC001_01_06_1 BEFORE TPM")
plt.show()


sns.scatterplot(data = CTC_length_TPM, x = np.log2(CTC_length_TPM["Transcript length"] + 1), y = np.log2(CTC_length_TPM["BC001_01_06_1"] +1))
plt.xlabel("Transcript length")
plt.ylabel("TPM counts")
plt.title("BC001_01_06_1 AFTER TPM")
plt.show()

"""# Добавим новые датасеты
Однако остальные найденные датасеты содержат в качестве гена не уникальный Gene ID, а Gene name.

В нашей таблице с соответствиями гена и длины транскрипта бывают гены, у которых разные id, но одинаковые названия (что конечно немного расстраивает концептуально), например так с геном SZRD1. Мы бы могли добавить индексы к таким генам и оставить как есть, но в большей части датасетов экспериментов с готовыми raw counts каунты представлены именно по gene name, а не по gene id, поэтому индекс в таком случае нам не поможет. Посмотрим, сколько существует генов, у которых одинаковые gene names, но при этом различная длина:
"""

names_genes_length = pd.read_csv('/content/genes_and_TRlength.txt', sep = '\t')
names_genes_length.rename(columns = {'Transcript length (including UTRs and CDS)' : 'Transcript length'}, inplace = True)
names_genes_length = names_genes_length.loc[names_genes_length.groupby(['Gene stable ID', 'Gene stable ID version', 'Gene name'])['Transcript length'].idxmax()]

names_genes_length.head()

gene_lengths_consistent = names_genes_length.groupby('Gene name')['Transcript length'].nunique()

gene_lengths_consistent.sort_values(ascending = False) # здесь информация про все гены, если стоит 1 -- значит только один раз встречается такое имя

inconsistent_gene_names = gene_lengths_consistent[gene_lengths_consistent > 1].index
print(f'Число генов с одинаковым именем и разной длиной: {len(inconsistent_gene_names)} из {names_genes_length.shape[0]} генов')

"""Так как таких генов немного относительно общей массы, а также зачастую эти гены кодируют не мРНК (например, U6), то мы можем их удалить из таблицы без сильных потерь, или же взять среднюю длину. Возьмем среднее, так как для некоторых таких генов, для которых посмотрели вручную длины для их названий, они довольно близкие."""

names_genes_length = names_genes_length.groupby('Gene name')['Transcript length'].mean().reset_index()

names_genes_length.head()

"""# 2) Embryonic stem cells

сырые каунты после HISAT2 и FeatureCounts
"""

!wget https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8567nnn/GSM8567246/suppl/GSM8567246%5FESCs%5Fcounts%2Etxt%2Egz

!gunzip GSM8567246_ESCs_counts.txt.gz

ESC_counts = pd.read_csv('GSM8567246_ESCs_counts.txt', sep = '\t')

ESC_counts.head()

ESC_counts = ESC_counts.reset_index()
ESC_counts = ESC_counts.rename(columns = {'index' : 'Gene name'})

# Добавим столбец с длиной транскрипта по имени гена
ESC_length = pd.merge(ESC_counts, names_genes_length[['Gene name', 'Transcript length']], on = 'Gene name', how = 'inner')

"""# Scatter plot for ESC"""

sns.scatterplot(data = ESC_length, x = np.log2(ESC_length["Transcript length"] + 1), y = np.log2(ESC_length["wd.z001.1.A2"] +1))
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("wd.z001.1.A2")
plt.show()

"""## Таблица для этих результатов

Потом сошьем вместе
"""

names_cells = list(ESC_length.columns)[1:-1]   # Следим за головой таблицы!
name_experiment = 16 * ['ESC Human']
organism = 16 * ['Homo sapiens']
align_t = 16 * ['HISAT2']
quant_t = 16 * ['FeatureCounts']

correlation_results_esc = pd.DataFrame({'Experiment' : name_experiment, 'Cell_ID' : names_cells, 'Organism' : organism, 'Alignment' : align_t, 'Quantification' : quant_t})

"""# Корреляция Спирмена"""

# Посчитаем корреляцию Спирмена для всех клеток по порядку

coeff_sp = []
p_val = []
for cell in names_cells:
  correlation, p_value = spearmanr(ESC_length[cell], ESC_length["Transcript length"])
  coeff_sp.append(correlation)
  p_val.append(p_value)

correlation_results_esc['Spearman coefficient'] = coeff_sp
correlation_results_esc['Spearman p-value'] = p_val

correlation_results_esc.head()

"""## Shuffle"""

ESC_length_sh = ESC_length.copy()
ESC_length_sh["Transcript length"] = ESC_length_sh["Transcript length"].sample(frac = 1, random_state = 30).reset_index(drop=True)

# Посчитаем корреляцию Спирмена для всех клеток по порядку, но ПОСЛЕ ПЕРЕМЕШИВАНИЯ

coeff_sp_sh = []
p_val_sh = []
for cell in names_cells:
  correlation, p_value = spearmanr(ESC_length_sh[cell], ESC_length_sh["Transcript length"])
  coeff_sp_sh.append(correlation)
  p_val_sh.append(p_value)

correlation_results_esc['Spearman coeff after SHUFFLE'] = coeff_sp_sh
correlation_results_esc['Spearman p-value after SHUFFLE'] = p_val_sh

"""# Критерий Колмогорова — Смирнова"""

# Квантиль 0.75 возьмем в качестве порога между длинными и короткими транскриптами. Создадим для них две отдельные таблицы

ESC_long = ESC_length[ESC_length["Transcript length"] >= 4365.75]
ESC_short = ESC_length[ESC_length["Transcript length"] < 4365.75]

# Посчитаем критерий КС для всех клеток по порядку

coeff_KS = []
p_val_KS = []
for cell in names_cells:
  statistic, p_value = stats.ks_2samp(ESC_short[cell], ESC_long[cell])
  coeff_KS.append(statistic)
  p_val_KS.append(p_value)

correlation_results_esc['KS coeff'] = coeff_KS
correlation_results_esc['KS p-value'] = p_val_KS

"""## Shuffle"""

# Квантиль 0.75 возьмем в качестве порога между длинными и короткими транскриптами. Создадим для них две отдельные таблицы

ESC_long_sh = ESC_length_sh[ESC_length_sh["Transcript length"] >= 4365.75]
ESC_short_sh = ESC_length_sh[ESC_length_sh["Transcript length"] < 4365.75]

# Посчитаем критерий КС для всех клеток по порядку, но ПОСЛЕ ПЕРЕМЕШИВАНИЯ

coeff_KS_sh = []
p_val_KS_sh = []
for cell in names_cells:
  statistic, p_value = stats.ks_2samp(ESC_short_sh[cell], ESC_long_sh[cell])
  coeff_KS_sh.append(statistic)
  p_val_KS_sh.append(p_value)

correlation_results_esc['KS coeff after SHUFFLE'] = coeff_KS_sh
correlation_results_esc['KS p-value after SHUFFLE'] = p_val_KS_sh

correlation_results_esc.head()

"""# Нормализация TPM"""

ESC_length_TPM = ESC_length.copy()

ESC_length_TPM['length kb'] = ESC_length_TPM['Transcript length'] / 1000

for cell in names_cells:
  ESC_length_TPM[cell] = ESC_length_TPM[cell] / ESC_length_TPM['length kb']
  scaling_factor = ESC_length_TPM[cell].sum() / 1e6
  ESC_length_TPM[cell] = ESC_length_TPM[cell] / scaling_factor

sns.scatterplot(data = ESC_length, x = np.log2(ESC_length["Transcript length"] + 1), y = np.log2(ESC_length["wd.z001.1.A2"] +1))
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("wd.z001.1.A2")
plt.show()


sns.scatterplot(data = ESC_length_TPM, x = np.log2(ESC_length_TPM["Transcript length"] + 1), y = np.log2(ESC_length_TPM["wd.z001.1.A2"] +1))
plt.xlabel("Transcript length")
plt.ylabel("TPM counts")
plt.title("wd.z001.1.A2 AFTER TPM")
plt.show()

"""# Склеим полученные таблицы с результатами"""

all_results = pd.concat([correlation_results, correlation_results_esc])

"""# Используемые функции

Можно было раньше, но так уж вышло

#### Спирмен: обычный и с перемешиванием
"""

def Spearman(df, names_cells):
  coeff_sp = []
  p_val = []
  for cell in names_cells:
    correlation, p_value = spearmanr(df[cell], df["Transcript length"])
    coeff_sp.append(correlation)
    p_val.append(p_value)
  return coeff_sp, p_val

"""#### Критерий Колмогорова - Смирнова: обычный и с перемешиванием"""

def KS(df, names_cells):
  df_long = df[df["Transcript length"] >= 4365.75]
  df_short = df[df["Transcript length"] < 4365.75]
  coeff_KS = []
  p_val_KS = []
  for cell in names_cells:
    statistic, p_value = stats.ks_2samp(df_short[cell], df_long[cell])
    coeff_KS.append(statistic)
    p_val_KS.append(p_value)
  return coeff_KS, p_val_KS

"""#### Нормализация TPM"""

def TPM(df):
  df_TPM = df.copy()
  df_TPM['length kb'] = df_TPM['Transcript length'] / 1000

  for cell in names_cells:
    df_TPM[cell] = df_TPM[cell] / df_TPM['length kb']
    scaling_factor = df_TPM[cell].sum() / 1e6
    df_TPM[cell] = df_TPM[cell] / scaling_factor
  return df_TPM

"""# 3) feeder-free extended pluripotent stem cells Homo sapiens
сырые каунты после HISAT2 и FeatureCounts
"""

!wget https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM8567nnn/GSM8567247/suppl/GSM8567247%5FffEPSCs%5Fcounts%2Etxt%2Egz

!gunzip GSM8567247_ffEPSCs_counts.txt.gz

EPSC_counts = pd.read_csv('GSM8567247_ffEPSCs_counts.txt', sep = '\t')

EPSC_counts = EPSC_counts.reset_index()
EPSC_counts = EPSC_counts.rename(columns = {'index' : 'Gene name'})
# Добавим столбец с длиной транскрипта по имени гена
EPSC_length = pd.merge(EPSC_counts, names_genes_length[['Gene name', 'Transcript length']], on = 'Gene name', how = 'inner')

EPSC_length.shape #параметры таблицы

"""## Scatter plot for EPSC"""

sns.scatterplot(data = EPSC_length, x = np.log2(EPSC_length["Transcript length"] + 1), y = np.log2(EPSC_length["wd.z001.1.E1"] +1))
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("wd.z001.1.E1")
plt.show()

"""## Корреляция Спирмена"""

names_cells = list(EPSC_length.columns)[1:-1]   # Следим за головой таблицы
name_experiment = 25 * ['EPSC Human']
organism = 25 * ['Homo sapiens']
align_t = 25 * ['HISAT2']
quant_t = 25 * ['FeatureCounts']

correlation_results_epsc = pd.DataFrame({'Experiment' : name_experiment, 'Cell_ID' : names_cells, 'Organism' : organism, 'Alignment' : align_t, 'Quantification' : quant_t})

epsc_sp = Spearman(EPSC_length, names_cells)
correlation_results_epsc['Spearman coefficient'] = epsc_sp[0]
correlation_results_epsc['Spearman p-value'] = epsc_sp[1]

"""**Shuffle**"""

EPSC_length_sh = EPSC_length.copy()
EPSC_length_sh["Transcript length"] = EPSC_length_sh["Transcript length"].sample(frac = 1, random_state = 30).reset_index(drop=True)

epsc_sp_sh = Spearman(EPSC_length_sh, names_cells)
correlation_results_epsc['Spearman coeff after SHUFFLE'] = epsc_sp_sh[0]
correlation_results_epsc['Spearman p-value after SHUFFLE'] = epsc_sp_sh[1]

"""## Критерий Колмогорова-Смирнова"""

epsc_KS = KS(EPSC_length, names_cells)
correlation_results_epsc['KS coeff'] = epsc_KS[0]
correlation_results_epsc['KS p-value'] = epsc_KS[1]

"""**Shuffle**"""

epsc_KS_sh = KS(EPSC_length_sh, names_cells)
correlation_results_epsc['KS coeff after SHUFFLE'] = epsc_KS_sh[0]
correlation_results_epsc['KS p-value after SHUFFLE'] = epsc_KS_sh[1]

correlation_results_epsc.head()

"""## TPM нормализация"""

EPSC_length_TPM = TPM(EPSC_length)

sns.scatterplot(data = EPSC_length, x = np.log2(EPSC_length["Transcript length"] + 1), y = np.log2(EPSC_length["wd.z001.1.E1"] +1))
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("wd.z001.1.E1")
plt.show()

sns.scatterplot(data = EPSC_length, x = np.log2(EPSC_length_TPM["Transcript length"] + 1), y = np.log2(EPSC_length_TPM["wd.z001.1.E1"] +1))
plt.xlabel("Transcript length")
plt.ylabel("TPM counts")
plt.title("wd.z001.1.E1 after TPM")
plt.show()

"""## Склейка"""

all_results = pd.concat([all_results, correlation_results_epsc])

"""# 4) DRG neurons Homo sapiens
сырые каунты после STAR и STAR quantMode GeneCounts
"""

!wget https://ftp.ncbi.nlm.nih.gov/geo/series/GSE249nnn/GSE249746/suppl/GSE249746%5FExpression%5Fmatrix%5Fraw%5Fcounts%2Ecsv%2Egz

!gunzip GSE249746_Expression_matrix_raw_counts.csv.gz

DRG_counts = pd.read_csv('GSE249746_Expression_matrix_raw_counts.csv')

"""Слишком уж здесь много образцов (более тысячи), возьмем случайные 52 клетки."""

gene_names = DRG_counts.iloc[:, 0]
random_columns = DRG_counts.iloc[:, 1:].sample(n=52, axis=1, random_state=30)
DRG_piece = pd.concat([gene_names, random_columns], axis=1)

DRG_piece = DRG_piece.rename(columns = {'Unnamed: 0' : 'Gene name'})

DRG_length = pd.merge(DRG_piece, names_genes_length[['Gene name', 'Transcript length']], on = 'Gene name', how = 'inner')

DRG_length.head()

"""## Scatter plot for DRG"""

sns.scatterplot(data = DRG_length, x = np.log2(DRG_length["Transcript length"] + 1), y = np.log2(DRG_length["N2-RT12-145"] +1))
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("N4-RT12-61")
plt.show()

"""## Корреляция Спирмена"""

names_cells = list(DRG_length.columns)[1:-1]   # Следим за головой таблицы!
name_experiment = 52 * ['DRG Human']
organism = 52 * ['Homo sapiens']
align_t = 52 * ['STAR']
quant_t = 52 * ['STAR quantMode']

correlation_results_drg = pd.DataFrame({'Experiment' : name_experiment, 'Cell_ID' : names_cells, 'Organism' : organism, 'Alignment' : align_t, 'Quantification' : quant_t})

drg_sp = Spearman(DRG_length, names_cells)
correlation_results_drg['Spearman coefficient'] = drg_sp[0]
correlation_results_drg['Spearman p-value'] = drg_sp[1]

"""**Shuffle**"""

DRG_length_sh = DRG_length.copy()
DRG_length_sh["Transcript length"] = DRG_length_sh["Transcript length"].sample(frac = 1, random_state = 30).reset_index(drop=True)

drg_sp_sh = Spearman(DRG_length_sh, names_cells)
correlation_results_drg['Spearman coeff after SHUFFLE'] = drg_sp_sh[0]
correlation_results_drg['Spearman p-value after SHUFFLE'] = drg_sp_sh[1]

"""## Критерий Колмогорова - Смирнова"""

drg_KS = KS(DRG_length, names_cells)
correlation_results_drg['KS coeff'] = drg_KS[0]
correlation_results_drg['KS p-value'] = drg_KS[1]

"""**Shuffle**"""

drg_KS_sh = KS(DRG_length_sh, names_cells)
correlation_results_drg['KS coeff after SHUFFLE'] = drg_KS_sh[0]
correlation_results_drg['KS p-value after SHUFFLE'] = drg_KS_sh[1]

correlation_results_drg.head()

"""## TPM нормализация"""

DRG_length_TPM = TPM(DRG_length)

sns.scatterplot(data = DRG_length, x = np.log2(DRG_length["Transcript length"] + 1), y = np.log2(DRG_length["N3-RL2-139"] +1))
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("N3-RL2-139")
plt.show()

sns.scatterplot(data = DRG_length, x = np.log2(DRG_length_TPM["Transcript length"] + 1), y = np.log2(DRG_length_TPM["N3-RL2-139"] +1))
plt.xlabel("Transcript length")
plt.ylabel("TPM counts")
plt.title("N3-RL2-139 after TPM")
plt.show()

"""## Склейка"""

all_results = pd.concat([all_results, correlation_results_drg])

all_results

"""# Мышиный референс
**Для разнообразия поработаем с мышками**
"""

mouse_length = pd.read_csv('/content/mouse_length.txt', sep = '\t')

mouse_length.rename(columns = {'Transcript length (including UTRs and CDS)' : 'Transcript length'}, inplace = True)

mouse_length.head()

mouse_length = mouse_length.loc[mouse_length.groupby(['Gene stable ID', 'Gene stable ID version', 'Gene name'])['Transcript length'].idxmax()]

"""Посмотрим, сколько генов с одинаковым именем у мыши:"""

gene_lengths_consistent_mouse = mouse_length.groupby('Gene name')['Transcript length'].nunique()
gene_lengths_consistent_mouse.sort_values(ascending = False) # здесь информация про все гены, если стоит 1 -- значит только один раз встречается такое имя

inconsistent_gene_names_mouse = gene_lengths_consistent_mouse[gene_lengths_consistent_mouse > 1].index
print(f'Число генов с одинаковым именем и разной длиной: {len(inconsistent_gene_names_mouse)} из {mouse_length.shape[0]} генов')

"""Как здорово! Хоть для какого-то животного хватило оригинальности. Все равно повторим наши действия и возьмем средние длины таких генов."""

mouse_names_length = mouse_length.groupby('Gene name')['Transcript length'].mean().reset_index()

"""# 5) Lung adenocarcinoma (LUAD) in Mus musculus
сырые каунты после HISAT2 и FeatureCounts
"""

!wget https://ftp.ncbi.nlm.nih.gov/geo/series/GSE245nnn/GSE245172/suppl/GSE245172%5FSMART%2Dseq2%5Frawcounts%2Exlsx

mouse_lung = pd.read_excel('GSE245172_SMART-seq2_rawcounts.xlsx')

mouse_lung = mouse_lung.rename(columns = {'Geneid' : 'Gene name'})

# Добавим столбец с длиной транскрипта по имени гена
mouse_lung = pd.merge(mouse_lung, mouse_names_length[['Gene name', 'Transcript length']], on = 'Gene name', how = 'inner')

mouse_lung.head()

"""## Scatter plot for LUAD"""

sns.scatterplot(data = mouse_lung, x = np.log2(mouse_lung["Transcript length"] + 1), y = np.log2(mouse_lung["ff_1"] +1))
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("ff_1")
plt.show()

"""## Корреляция Спирмена

Сделаем пока отдельную мышиную табличку
"""

names_cells = list(mouse_lung.columns)[1:-1]
name_experiment = 10 * ['Lung mus']
organism = 10 * ['Mus musculus']
align_t = 10 * ['HISAT2']
quant_t = 10 * ['FeatureCounts']

mouse_correlation_res_lung = pd.DataFrame({'Experiment' : name_experiment, 'Cell_ID' : names_cells, 'Organism' : organism, 'Alignment' : align_t, 'Quantification' : quant_t})

lung_sp = Spearman(mouse_lung, names_cells)
mouse_correlation_res_lung['Spearman coefficient'] = lung_sp[0]
mouse_correlation_res_lung['Spearman p-value'] = lung_sp[1]

"""**Shuffle**"""

mouse_lung_length_sh = mouse_lung.copy()
mouse_lung_length_sh["Transcript length"] = mouse_lung_length_sh["Transcript length"].sample(frac = 1, random_state = 30).reset_index(drop=True)

lung_sp_sh = Spearman(mouse_lung_length_sh, names_cells)
mouse_correlation_res_lung['Spearman coeff after SHUFFLE'] = lung_sp_sh[0]
mouse_correlation_res_lung['Spearman p-value after SHUFFLE'] = lung_sp_sh[1]

"""## Критерий Колмогорова - Смирнова"""

mouse_lung_KS = KS(mouse_lung, names_cells)
mouse_correlation_res_lung['KS coeff'] = mouse_lung_KS[0]
mouse_correlation_res_lung['KS p-value'] = mouse_lung_KS[1]

"""**Shuffle**"""

mouse_lung_KS_sh = KS(mouse_lung_length_sh, names_cells)
mouse_correlation_res_lung['KS coeff after SHUFFLE'] = mouse_lung_KS_sh[0]
mouse_correlation_res_lung['KS p-value after SHUFFLE'] = mouse_lung_KS_sh[1]

mouse_correlation_res_lung.head()

"""## TPM нормализация"""

mouse_lung_TPM = TPM(mouse_lung)

sns.scatterplot(data = mouse_lung, x = np.log2(mouse_lung["Transcript length"] + 1), y = np.log2(mouse_lung["ff_1"] +1))
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("ff_1")
plt.show()

sns.scatterplot(data = mouse_lung, x = np.log2(mouse_lung_TPM["Transcript length"] + 1), y = np.log2(mouse_lung_TPM["ff_1"] +1))
plt.xlabel("Transcript length")
plt.ylabel("TPM counts")
plt.title("ff_1 after TPM")
plt.show()

"""# 6) Blastomere Mus musculus
сырые каунты после STAR и STAR quantMode GeneCount
"""

!wget https://ftp.ncbi.nlm.nih.gov/geo/series/GSE241nnn/GSE241089/suppl/GSE241089%5Fraw%5Fcount%5Fmatrix%5Fall%5Fblastomeres%2Ecsv%2Egz

!gunzip GSE241089_raw_count_matrix_all_blastomeres.csv.gz

blast_mouse = pd.read_csv('GSE241089_raw_count_matrix_all_blastomeres.csv')

blast_mouse = blast_mouse.rename(columns = {'gene' : 'Gene name'})

# Добавим столбец с длиной транскрипта по имени гена
blast_length = pd.merge(blast_mouse, mouse_names_length[['Gene name', 'Transcript length']], on = 'Gene name', how = 'inner')

"""## Корреляция Спирмена


"""

names_cells = list(blast_length.columns)[1:-1]   # Следим за головой таблицы!
name_experiment = 125 * ['Lung mus']
organism = 125 * ['Mus musculus']
align_t = 125 * ['STAR']
quant_t = 125 * ['STAR quant Mode']

mouse_correlation_res_blast = pd.DataFrame({'Experiment' : name_experiment, 'Cell_ID' : names_cells, 'Organism' : organism, 'Alignment' : align_t, 'Quantification' : quant_t})

blast_sp = Spearman(blast_length, names_cells)
mouse_correlation_res_blast['Spearman coefficient'] = blast_sp[0]
mouse_correlation_res_blast['Spearman p-value'] = blast_sp[1]

"""**Shuffle**"""

blast_length_sh = blast_length.copy()
blast_length_sh["Transcript length"] = blast_length_sh["Transcript length"].sample(frac = 1, random_state = 30).reset_index(drop=True)

blast_sp_sh = Spearman(blast_length_sh, names_cells)
mouse_correlation_res_blast['Spearman coeff after SHUFFLE'] = blast_sp_sh[0]
mouse_correlation_res_blast['Spearman p-value after SHUFFLE'] = blast_sp_sh[1]

"""## Критерий Колмогорова - Смирнова"""

blast_KS = KS(blast_length, names_cells)
mouse_correlation_res_blast['KS coeff'] = blast_KS[0]
mouse_correlation_res_blast['KS p-value'] = blast_KS[1]

"""**Shuffle**"""

blast_KS_sh = KS(blast_length_sh, names_cells)
mouse_correlation_res_blast['KS coeff after SHUFFLE'] = blast_KS_sh[0]
mouse_correlation_res_blast['KS p-value after SHUFFLE'] = blast_KS_sh[1]

mouse_correlation_res_blast.head()

"""## TPM нормализация"""

blast_length.head()

blast_length_TPM = TPM(blast_length)

sns.scatterplot(data = blast_length, x = np.log2(blast_length["Transcript length"] + 1), y = np.log2(blast_length["Plate1_H04-ICSI_Eq-37b"] +1))
plt.xlabel("Transcript length")
plt.ylabel("Raw counts")
plt.title("Plate1_H04-ICSI_Eq-37b")
plt.show()

sns.scatterplot(data = blast_length_TPM, x = np.log2(blast_length_TPM["Transcript length"] + 1), y = np.log2(blast_length_TPM["Plate1_H04-ICSI_Eq-37b"] +1))
plt.xlabel("Transcript length")
plt.ylabel("TPM counts")
plt.title("Plate1_H04-ICSI_Eq-37b after TPM")
plt.show()

"""# Сведем мышиные таблицы"""

all_results_mouse = pd.concat([mouse_correlation_res_lung, mouse_correlation_res_blast])

"""# Посмотрим на таблицы с результатами:
У нас есть таблица отдельно по людям и отдельно по мышам. Сравним средние значения корреляции и критерия КС:
"""

mean_sp_mouse = all_results_mouse['Spearman coefficient'].mean()
median_sp_mouse = all_results_mouse['Spearman coefficient'].median()
mean_sp_human = all_results['Spearman coefficient'].mean()
median_sp_human = all_results['Spearman coefficient'].median()

print(mean_sp_mouse, median_sp_mouse)
print(mean_sp_human, median_sp_human)

mean_ks_mouse = all_results_mouse['KS coeff'].mean()
median_ks_mouse = all_results_mouse['KS coeff'].median()
mean_ks_human = all_results['KS coeff'].mean()
median_ks_human = all_results['KS coeff'].median()

print(mean_ks_mouse, median_ks_mouse)
print(mean_ks_human, median_ks_human)

"""Значения похожи, хоть для мыши и чуть выше.
Но для человеческих образцов было два (от одной лаборатории) эксперимента с SC клетками, где коэффициент корреляции заметно ниже остальных экспериментов. Вероятно из-за него и падает среднее число.   

В отличие от других человеческих клеток, SC клетки были выравненны HISAT2.
Таким же способом были выравнены результаты для клеток LUAD мыши. Все остальные же образцы, как человеческие, так и мышиные, были выравнены STAR. Разницу для человеческих клеток при применении STAR и HISAT2 мы уже заметили, проверим для мыши:
"""

print(f'{mouse_correlation_res_lung["Spearman coefficient"].mean()} - среднее для HISAT2, {mouse_correlation_res_blast["Spearman coefficient"].mean()} - среднее для STAR')

"""Среднии довольно сильно отличаются. Возможно, метод выравнивания HISAT2 более устойчив к length bias, чем STAR

Соединим полученные таблицы и сделаем поправку на множественность Бенджамини-Хохберга.
"""

final_res_table = pd.concat([all_results, all_results_mouse])

from statsmodels.stats.multitest import multipletests

pvalues = final_res_table['Spearman p-value']
fdr_res = multipletests(pvalues, method='fdr_bh')

fdr_res[0]

pvalues_ks = final_res_table['KS p-value']
fdr_res_ks = multipletests(pvalues_ks, method='fdr_bh')

fdr_res_ks[0]

"""Все наши результаты корреляции Спирмена прошли порог adjusted p-value. Тогда можем вывести средние и медианные коэффициенты"""

fin_mean_sp = final_res_table["Spearman coefficient"].mean()
fin_median_sp = final_res_table["Spearman coefficient"].median()

fin_mean_ks = final_res_table["KS coeff"].mean()
fin_median_ks = final_res_table["KS coeff"].median()

print(f'Cреди 235 scRNA-seq средний коэффициент корреляции между длиной транскрипта и каунтом равен {fin_mean_sp}, а медианный - {fin_median_sp}')

print(f'Cреди 235 scRNA-seq средний критерий КС для групп с короткими и длинными транскриптами равен {fin_mean_ks}, а медианный - {fin_median_ks}')